{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f58cea",
   "metadata": {},
   "source": [
    "### Part 1:\n",
    "I've chosen Qwen3-embedding-0.6B because Qwen3-embedding-8B achieved state-of-art performance and Qwen3-embedding-0.6B showed outstanding results for small embedder model.\n",
    "https://youtu.be/hize6rD6Afk?si=kjCVotpzqbECXFfi - video that confirms my opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "  repo_id=\"Qwen/Qwen3-Embedding-0.6B-GGUF\",\n",
    "  filename=\"Qwen3-Embedding-0.6B-Q8_0.gguf\",\n",
    "  embedding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b86e2",
   "metadata": {},
   "source": [
    "### Part 2:\n",
    "Selecting needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffd472",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('netflix_reviews.csv')\n",
    "data = data[['content','score']]\n",
    "\n",
    "prep_data = data.groupby(\"score\").apply(lambda x: x.sample(400, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# Making sure that our data is uniformly distributed\n",
    "print(prep_data['score'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a70b99",
   "metadata": {},
   "source": [
    "### Part 3:\n",
    "Adding new column with embedding retrieved from the Qwen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data['embedders'] = prep_data['content'].apply(lambda x: llm.create_embedding(x)['data'][0]['embedding'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939fd92",
   "metadata": {},
   "source": [
    "### Part 4:\n",
    "Implementing minkowski distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b11cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I used minkowski distance because if the parameter(p)\n",
    "# p = 2 - it becomes Euclidian distance\n",
    "# p = 1 - it becomes Manhattan distance\n",
    "# p = 1.5 - assume to be value of p for Minkowski distance\n",
    " \n",
    "def minkowski_dist(x:list, y:list, p:int = 1.5):\n",
    "    if p < 1:\n",
    "        raise ValueError(f\"Parameter p must be greater than 1 (p={p})\")\n",
    "    if len(x) != len(y):\n",
    "        raise ValueError(f\"Parameters x and y must be same size (x={len(x)}, y={len(y)})\")\n",
    "    \n",
    "    distance = 0\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        distance += np.pow(np.abs(x[i] - y[i]), p)\n",
    "    \n",
    "    return np.pow(distance, 1/p)\n",
    "\n",
    "# # Checking the correctness of the function (should be 5 since it Egypt triangle)\n",
    "# print(minkowski_dist([0, 0], [3, 4], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64e4ad",
   "metadata": {},
   "source": [
    "Implementing function that will perform k-means++ clusterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0e7cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(k: int, data: list, dist_p: int, max_iterations=100):\n",
    "    \n",
    "    #initializing center points via k-means++\n",
    "    centers = [data[np.random.randint(len(data))].copy()]\n",
    "        \n",
    "    for _ in range(1, k):\n",
    "        distances = []\n",
    "        for point in data:\n",
    "            min_dist = min(minkowski_dist(point, center, dist_p) for center in centers)\n",
    "            distances.append(min_dist)\n",
    "        \n",
    "        probabilities = np.array(distances) / np.sum(distances)\n",
    "        next_center_idx = np.random.choice(len(data), p=probabilities)\n",
    "        centers.append(data[next_center_idx].copy())\n",
    "    \n",
    "    #making groups for points of different clusters\n",
    "    groups = [[] for _ in range(k)]\n",
    "    \n",
    "    #calculating the distance and assigning points to the corresponding group with the closest center \n",
    "    for point in data:\n",
    "        distances = [minkowski_dist(center, point, dist_p) for center in centers]\n",
    "        closest_center_idx = np.argmin(distances)\n",
    "        groups[closest_center_idx].append(point)\n",
    "    \n",
    "    \n",
    "    iteration = 0\n",
    "    while iteration < max_iterations:\n",
    "        \n",
    "        #finding new center as the mean of all points assigned to it's group\n",
    "        new_centers = []\n",
    "        for i in range(k):\n",
    "            if len(groups[i]) == 0:\n",
    "                new_centers.append(centers[i])\n",
    "            else:\n",
    "                new_center = []\n",
    "                for dim in range(len(centers[0])):\n",
    "                    new_center.append(np.mean(np.array(groups[i])[:, dim]))\n",
    "                new_centers.append(new_center)\n",
    "        \n",
    "        #reassembling the group with new centers\n",
    "        new_groups = [[] for _ in range(k)]\n",
    "        for point in data:\n",
    "            distances = [minkowski_dist(center, point, dist_p) for center in new_centers]\n",
    "            closest_center_idx = np.argmin(distances)\n",
    "            new_groups[closest_center_idx].append(point)\n",
    "        \n",
    "        if groups == new_groups:\n",
    "            print(\"Ended with no changes in groups\")\n",
    "            break\n",
    "            \n",
    "        centers, groups = new_centers, new_groups\n",
    "        iteration += 1\n",
    "    \n",
    "    return centers, groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a2f82",
   "metadata": {},
   "source": [
    "Retrieving the results of clusterization with different distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"euclidian\":tuple(k_means(5, prep_data['embedders'], 2)),\n",
    "    \"minkowski\":tuple(k_means(5, prep_data['embedders'], 1.5)),\n",
    "    \"manhattan\":tuple(k_means(5, prep_data['embedders'], 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fd01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['euclidian'])\n",
    "print(results['minkowski'])\n",
    "print(results['manhattan'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
